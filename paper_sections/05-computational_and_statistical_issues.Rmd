
# V: Statistical and computational issues

Which of the five models should you choose for a given data set? There are two major trade-offs to take into account. The first is the bias-variance trade-off: more complex models can account for more fluctuations in the data, but also tend to give more variable predictions, and can overfit.  The second tradeoff is model complexity versus computer time: more complex models can include more potential sources of variation and give more information about a given data set, but will generally take more time and computational resources to fit and debug. We will discuss both of these trade-offs in this section.



## Bias-variance tradeoffs

The bias-variance tradeoff is a fundamental concept in classical statistical
analysis. When trying to estimate any value (in the cases we are focusing on, a
smooth functional relationship between predictors and data), bias measures how
on average an estimate is from the true value of the thing we are trying to
estimate, and the variance of an estimator corresponds to how much that
estimator would fluctuate if applied to multiple different samples taken from the
same population. These two properties tend to be traded off when fitting models;
for instance, rather than estimating a population mean from data, we could
simply use a fixed value regardless of the observed data. This estimate would
have no variance (as it is always the same) but would have high bias unless the
true population mean happened to equal zero [^mean_note]. The core insight into
why penalization is useful is that the penalty term slightly increases the bias
but can substantially decrease the variance of an estimator, relative to its
unpenalized version [CITE: Effron and Morris 1977].

In GAMs and HGLMs, the bias-variance tradeoff is managed by the penalty terms
(random effect variances in HGLM terminology). Larger penalties correspond to
lower variance, as the estimated function is unable to wiggle a great deal, but
also correspond to higher bias unless the true function is close to the null
space for a given smoother (e.g. a straight line for thin-plate splines with 2nd
derivative penalties, or zero for a standard random effect). The computational
machinery used by mgcv to fit smooth terms is designed to find penalty terms
that best trade off bias for variance to find a smooth that can effectively to
predict new data.

The bias--variance tradeoff comes into play with HGAMs when choosing whether to
fit separate penalties for each group level or assign a common penalty for all
group levels (i.e. deciding between models 2 & 3 or models 4 & 5). If the
functional relationships we are trying to estimate for different group levels
actually vary in how wiggly they are, setting the penalty for all group-level
smooths equal (models 2&4) will either lead to overly variable estimates for the
least variable group levels, overly smoothed (biased) estimates for the most
wiggly terms, or a mixture of these two, depending on how the fitting criteria
used (ML, REML, or GCV) determines where the optimal smoothing parameter should
be set. 

```{r single_smooth_bias, echo=F, message=F, warning=F, cache=T}
source("../code/overfit_from_pooling.R")
```


We developed a simple numerical experiment to determine whether mgcv fitting
criteria tend to set estimated smoothness penalties high or low in the presence
of among-group variability in smoothness. We simulated data from five different
groups, with all groups having the same levels of the covariate x, ranging from
0 to $2\pi$. For each group, the true function relating x to y was a sine wave,
but the frequency varied from 0.25 (equal to half a cycle across the range of x)
to 4 (corresponding to 4 full cycles across the range). We added normally
distributed error to all y-values, with a standard deviation of 0.2. We then fit
both model 4 (where all curves were assumed to be equally smooth) and model 5
(with varying smoothness) to the entire data set, using REML criteria to
estimate penalties. For this example (Fig. \ref{fig:var_pen}a), requiring equal
smoothness for all group levels resulted mgcv underestimating the penalty for
the lowest frequency (most smooth) terms, but accurately estimating the true
smoothness of the highest frequency terms as measured by the squared second derivative
of the smooth fit versus that of the true function (Fig. \ref{fig:var_pen}b).

This implies that assuming equal smoothness will tend to lead to underestimating
the true smoothness of low-variability terms, and thus leading to more variable
estimates of these terms. If this is a potential issue, we recommend fitting
both models and using the model evalution techniques discussed in Section IV to
determine if there is evidence for among-group variability in smoothness. For
instance, the AIC for model 4 fit to this data is `r round(AIC(mod1))`, whereas
it is `r round(AIC(mod2))`, implying a substantial improvement in fit by
allowing smoothness to vary. However, it may be the case that there is too few
data points per group to estimate seperate smoothness levels, in which case
model 2 or model 4 may still be the better option even in the face of varying
smoothness.

The ideal case would be to assume that among group penalties follow their own
distribution (estimated from the data), to allow variation in smoothness while
still getting the benefit of pooling information on smoothness between groups.
However, this is currently not implemented in mgcv (and would be difficult to
set up via mgcv's method of structuring penalties). It is possible to set up
this type of varying penalty model in flexible Bayesian modelling software such
as Stan or INLA (see below for a discussion of these tools), but how to set up
this type of model has not been well studied, and is  beyond the scope of this
paper.


 
[^mean_note]: While this example may seem contrived, this is exactly what happens
when we assume a given fixed effect is equal to zero (and thus exclude it from a model). 


```{r single_smooth_bias_plot, echo=F,  fig.width=6, fig.height=6,message=F, warning=F, cache=T, fig.cap="\\label{fig:var_pen}plotting example"}
print(cowplot::plot_grid(overfit_vis_plot,deriv_plot,ncol = 1,labels = "auto"))
```



It may seem like there is also a bias--variance tradeoff between choosing to use
a single global smoother (model 1) or a global smoother plus group-level terms
(model 2-3), as in model 1, all the data is used to estimate a single smooth
term, and thus should have lower variance than models 2-3, but higher bias for
any given group in the presence of inter-group functional variability. However,
in practice, this tradeoff will already be handled by mgcv via estimating
penalties; if there are no average differences between functional responses,
mgcv will penalize the group--specific functions toward zero, and thus toward
the global model. The choice between using model 1 versus models 2-3 should
generally be driven by  computational costs; model 1 is typically much faster to
fit than models 2-3, even in the absence of among--group differences, so if
there is no need to estimate inter-group variability, model 1 will typically be
more efficient. 

A similar issue exists when choosing between models 2/3 and
4/5; if all group levels have very different functional shapes, the global term
will get penalized toward zero in models 2/3, so they will reduce to models 4/5. 
Again, the choice to include a global term or not should be made based on scientific 
considerations (is the global term of interest to estimate) and computational 
considerations (which we will discuss next).  


## Complexity -- computation tradeoffs

GAMs and GLMMs have substantially increased the range of flexible models available to the average researcher, and the HGAM models we discussed in section III extend on this broad base. However, the more flexible a model is, the larger an effective parameter space any fitting software has to search to find parameters that can predict the observed data. While numerical algorithms for solving complex models are always improving, it can still be surprisingly easy to use up massive computational resources trying to fit a model to even relatively small datasets. While we typically want to choose a model based on model fit (see above and section IV) and our goals for what the model will be used for, computing resources can often act as an effective upper limit on possible model complexity. Fitting an HGAM means adding extra computational complexity on top of either a GAM model with only global terms or a GLMM without smooth terms. For a given data set (with a fixed number `n` data points) and assuming a fixed family and link function, the time it takes to compute a given HGAM will depend, roughly, on four factors: the number of basis functions to be estimated, the number of smooth penalties to be estimated, whether the model needs to estimate both a global smooth and groupwise smooths, and the algorithm used to estimate parameters and fitting criteria used. 


The most straightforward factor that will affect the amount of computational resources is the number of parameters in the model. Adding group-level smooths (moving from model 1 to 2-5) means that there will be more regression parameters to estimate, since each grouping level needs a separate coefficient for each basis function in the smooth. For a dataset with `g` different groups and `n` data points, fitting a model will just a global smooth, `y~s(x,k=k)` will require only `k` coefficients, and takes $\mathcal{O}(nk^2)$ operations[^bigO] to evaluate, but fitting the same data using a group-level smooth (model 4, `y~s(x,fac,bs="fs",k=k)`) will require $\mathcal{O}(nk^2g^2)$ operations to evaluate; in effect, adding a group-level smooth will increase computational time by an order of the number of groups squared[^globalnpar]. The effect of this is visible in the examples we fit in section III when comparing the number of coefficients and relative time it takes to compute model 1 versus the other models (Table \ref{tab:comp_time}). One way to deal with this issue would be to reduce the number of basis functions (`k`) used when fitting group-level smooths when the number of groups is large; in effect, this would increase the flexibility of the model to accommodate inter-group differences, while reducing its ability to model variance within any given group. It can also make sense to use more computationally efficient basis functions when fitting large data sets, such as p-splines or cubic splines, rather than thin-plate splines, as thin-plate splines can take a substantial amount of overhead to compute the actual basis functions to use [CITE].


[^bigO]:To understand the effects of these terms, we will use "big-O" notation; when we say a given computation is of order $\mathcal{O}(n\log{}n)$, it means that, for that computation, as $n$ gets large, the amount of time the computation will take will grown proportionally to $n\log{}n$, so more quickly than linearly with $n$, but not as fast as $n$ squared. 

[^globalnpar]: Including a global smooth (models 2-3) or not (models 4-5) will not generally substantially affect the number of coefficients needed to estimate (compare the number of coefficients in Table \ref{tab:comp_time}, model 2 vs. model 4, or model 3 versus model 5). Adding a global term will only add at most `k` extra terms, and it actually ends up being less that that, as `mgcv` drops basis functions from co-linear smooths to ensure that the model matrix is full rank.


Adding additional smoothing parameters (moving from model 2 to model 3, or moving from model 4 to 5) is even more costly than increasing the number of coefficients to estimate, as estimating smoothing parameters is computationally intensive [CITE Wood 2011]. This means that models 2 and 4 will generally be substantially faster than 3 and 5 when the number of groups is reasonably large, as models 3 and 5 fit a separate set of penalties for each group level. The effect of this is visible in comparing the time it takes to fit model 2 to model 3 (which has a smooth for each group) or models 4 and 5 for the example data (Table \ref{tab:comp_time}). Note that this will not hold for every model, though; for instance, model 5 takes less time to fit the bird movement data than model 4 does (Table \ref{tab:comp_time}B). 



```{r comp_calc, echo=F,  fig.width=4, fig.height=6,message=F, warning=F, cache=T}
#Note: this code takes quite a long time to run! It's fitting all 10 models.
#Run once if possible, then rely on the cached code. There's a reason it's split off from the rest of the chunks of code.
source("../code/Sec_5_computational_code.R")
```


```{r comp_calc_table, echo=F,  fig.width=4, fig.height=6,message=F, warning=F, cache=T}
library(kableExtra)
library(knitr)
comp_resources_table =comp_resources %>%
  ungroup()%>%
  arrange(data_source,model_number)%>%
  transmute(data_source =data_source, model=model_number,
            `relative time` = time,`coefficients` = n_coef,
            `penalties` = n_smooths
            )%>%
  group_by(data_source) %>%
  mutate(`relative time` = `relative time`/`relative time`[1],#scales processing time relative to model 1 
         `relative time` = ifelse(`relative time`<10, signif(`relative time`,1), signif(`relative time`, 2)) #rounds to illustrate differences in timing.
         )%>%
  ungroup()%>%
  select(-data_source)

kable(comp_resources_table,format ="latex", caption="\\label{tab:comp_time}")%>% #NOTE: change format to "latex" when compiling to pdf, "html" when compiling html
  kable_styling(full_width = F)%>%
  add_header_above(c(" " = 1," "=1, "# of terms"=2))%>%
  group_rows("A. CO2 data", 1,5)%>%
  group_rows("B. bird movement data", 6,10)

```



## Alternative formulations: bam, gamm, and gamm4 (with a brief foray into Bayes)

When fitting models with large numbers of different group levels, it is often 
possible to speed up computation substantially by using one of the alternative fitting
algorithms available through mgcv. 

The first tool available, that requires the least changes to your code compared
to the base `gam` function, is the `bam` function. This function is designed to
improve  performance when fitting data sets with large amounts of data. It uses
two tools to do this. First, it saves on the amount of memory needed to compute
a given model by using a random subset of the data to calculate the basis
functions for the smoothers, then breaking the data up into blocks and updating
model fit within each block [*CITE*]. While this is primarily designed to reduce
the amount of memory needed to fit these models, it can also substantially
reduce computation time. Second, the `bam` function, when fitting using its
default "fREML" (for "Fast REML") method, you can use the `discrete` when
fitting the model. This option causes bam to simplify each covariate to a set of
discrete levels (instead of a continuous range), substantially reducing the
amount of computation needed. Setting "discrete = TRUE" lets `bam` estimate the
number of bins to use for each covariate. It is also possible to manually
specify the number of bins by passing `discrete` a vector of values. See
`?mgcv::bam` for more details.

It also takes more computational overhead compared to `gam` to set a `bam` model
up, so for small numbers of groups, it can actually be slower than `gam` (Figure
[*alt_timing*]), however, as the number of groups increases, computational time
for `bam` increases more slowly than for `gam`; in our simulation tests, when
the number of groups is greater than 16, `bam` can be upward of an order of
magnitude faster (Figure [*alt_timing*]). Note that `bam` can be somewhat less
computationally stable when estimating these models (i.e. less likely to
converge) so it does typically make sense to still use `gam` for smaller data
sets.


The second option is to fit these models using one of two dedicated mixed effect
model estimation packages, `nlme` and `lme4`. The `mgcv` package includes the
function `gamm` that allows you to call `nlme` to solve a given GAM,
automatically handling the transformation of smooth terms into random effects
(and back into basis-function representations for plotting and other statistical
analyses). To use `lme4`, you will have to install the `gamm4` package, and use
the `gamm4` function from this package. Using `gamm` or `gamm4` to fit models
rather than `gam` can substantially speed up computation when the number of
groups is large, as both `nlme` and `lme4` take advantage of the sparse
structure of the random effects, where most basis functions will be zero for
most groups (i.e. any group-specific basis function will only take a non-zero
value for observations in that group level). As with `bam`, `gamm` and `gamm4`
are generally slower than `gam` for fitting HGAMs when the number of group
levels is small (in our simulations, <8 group levels), however they do show
substantial speed improvements even with a moderate number of groups, and were
as fast as or faster to calculate than *bam* for all numbers of grouping levels
we tested (Figure [*alt_timing*])[^parallel].

[^parallel]: It is also possible to speed up both `gam` and `bam` by using
multiple processors in parallel, whereas this is not currently possible for
`gamm` and `gamm4`. For large numbers of grouping levels, this should speed up
computation as well, at the cost of using more memory. However, computation time
will likely not decline linearly with the number of cores used, since not all
model fitting sets are parallizable, and performance of the cores can vary. As
parallel processing can be complicated and dependent on the type of computer
you are using to configure properly, we do not go into how to use these methods
here. The help file `?mgcv::mgcv.parallel` explains how to use parallel
computations for `gam` and `bam` in detail.




```{r alt_model_timing, echo=F,  fig.width=6, fig.height=4,message=F, warning=F, cache=T}
source("../code/Sec_5_alt_model_timing.R")
```

```{r alt_model_timing_plot, echo=F,  fig.width=6, fig.height=4,message=F, warning=F, cache=T,fig.cap = "Elapsed time to estimate the same model using each of the four approaches. Each data set was generated with 20 observations per group using a unimodal global function and random group-specific functions consisting of an intercept, a quadratic term, and logistic trend for each group. Observation error was normally distributed. Models were fit using model 2: y~s(x,k=10, bs='cp') + s(x,fac, k=10, bs='fs', xt=list(bs='cp'),m=1) All models were run on a single core."}

timing_plot = ggplot(aes(n_groups, timing, color=model, linetype= model), 
                     data=fit_timing_long)+
  geom_line()+
  geom_point()+
  scale_color_manual(values = c("black", "#1b9e77","#1b9e77", "#d95f02", "#7570b3"))+
  scale_linetype_manual(values =c(1,1,2,1,1))+
  scale_y_log10("run time (seconds)", breaks = c(0.1,1,10,100), labels = c("0.1", "1","10", "100"))+
  scale_x_log10("number of groups", breaks = c(2,8,32,128))+
  
  theme_bw()+
  theme(panel.grid.minor  = element_blank(),panel.grid.major.x = element_blank(),
        legend.position = "bottom")

print(timing_plot)

```


Setting up models 1-5 in `bam` uses the same code as we have previously covered;
the only difference is that you use the `bam` instead of `gam` function, and
have the additional option of discretizing your covariates. The advantage of
this approach is that `bam` allows you to use almost all of the same families
available to the `gam` function, and `bam` model output can be evaluated using
the same functions (e.g. `summary`, `AIC`, `plot`, etc.) so it is simple to
substitute for `gam` if you need to speed a model up.

Both `gamm` and `gamm4` require at least a few changes to how you code models.
First, there are a few limitations on how you are able to specify models 1-5 in both frameworks. Factor smooth (`bs="fs"`) basis setups work in both `gamm` and `gamm4`. However, as the `nlme` package does not support crossed random effects, it is not possible to have two "fs" terms for the same grouping variable in `gamm` models (e.g. `y~s(x1, grp,bs="fs"+s(x2, grp, bs="fs")`. These type of crossed random effects are allowed in `gamm4`. The use of `te` and `ti` terms are not possible in `gamm4` however, due to 
issues with how random effects are specified in the `lme4` package, making it impossible to code models where multiple penalties apply to a single basis function. Instead, for
multidimensional group-level smooths, the alternate function `t2` needs to be used
to generate these terms, as it creates tensor products with only a single penalty for
each basis function (see `?mgcv::t2` for details on these smoothers, and [*CITE*] for 
the theoretical basis behind this type of tensor product). So for instance, model 2 for the 
bird movement data we discussed in section III would need to be coded as:

```
bird_mod4_gamm4 = gamm4(count ~ t2(week,latitude,species, bs= c("cc", "tp","re"), 
                     k=c(10,10,6),m = 2), 
                data= bird_move, family= poisson)
```


These packages also do not support the same range of families for the dependent
variable; `gamm` only supports non-Gaussian families by using a fitting method
called penalized quasi-likelihood (PQL) that is slower and not as numerically
stable as the methods used in `gam`, `bam`, and `gamm4`. Non-Gaussian families
are well supported by `lme4` (and thus `gamm4`), but can only fit them using
marginal likelihood (ML) rather than REML, so may tend to over-smooth relative
to `gam` using REML estimation. Further, neither `gamm` nor `gamm4` supports
several of the extended families available through `mgcv`, such as zero-inflated,
negative binomial, or ordered categorical and multinomial distributions. 


## Estimation issues when fitting both global and groupwise smooths

When fitting models with separate global and groupwise smooths (models 2 and 3),
one issue to be aware of is concurvity between the global smooth and groupwise
terms. Concurvity measures how well one smooth term can be approximated by some
combination of the other smooth terms in the model (see `?mgcv::concurvity` for
details). For models 2 and 3, the global term is entirely concurve with the
groupwise smooths. This is because, in the absence of the global smooth term, it
would be possible to recreate that average effect by shifting all the groupwise
smooths so they were centered around the global mean. In practical terms, this
has the consequence of increasing uncertainty around the global mean relative to
a model with only a global smooth. In some cases, it can result in the estimated
global smooth being close to flat, even in simulated examples with a known
strong global effect. This concurvity issue may also increase the time it takes
to fit these models (for example, compare the time it takes to fit models 3 and
5 in Table \ref{tab:comp_time}). That these models can still be estimated is
because of the penalty terms;  all of the methods we have discussed for fitting
model 2 ("fs" terms or random effect tensor products) automatically create a
penalty for the null space of the group-level terms, so that only the global
term has its own unpenalized null space, and both the REML and ML criteria work
to balance penalties between nested smooth terms (this is why nested random
effects can be fitted). We have noted, however, that `mgcv` still occasionally
finds degenerate solutions with simulated data where the fitted global term ends
up over-smoothed.

What we recommend to avoid this issue is to use a combination of smoother choice and setting model degrees of freedom so that the groupwise terms are either slightly less flexible or have a smaller null space. For instance, in the examples in section III, we used smoothers with an unpenalized null space (standard thin-plate splines) for the global smooth and ones with no null space for the groupwise terms[^gsnull]. When using thin-plate splines, it may also help to use splines with a lower order of derivative penalized in the groupwise smooths than the global smooths, as lower-order "tp" splines have fewer basis functions in the null space. For example, we used `m=2` (penalizing squared second derivatives) for the global smooth, and `m=1` (penalizing squared first derivatives) for groupwise smooths in models 2 and 3. Another option would be to use a lower number of basis functions (`k`) for groupwise relative to global terms, as this will reduce the maximum flexibility possible in the groupwise terms. We do caution that these are just rules of thumb. As of this writing, there is no published work looking what the effect of adding groupwise smooths has on the statistical properties of estimating a global smooth. In cases where an accurately estimated global smooth is essential, we recommend either fitting model 1, or using Markov Random Fields (Appendix A) and calculate the global smooth by averaging across grouping levels.

[^gsnull]: For model 2, the "fs" smoother, and tensor products of random effect ("re") and other smooth terms do not have a penalized null space by construction (they are full rank), as noted above. For model 3 groupwise terms, we used basis types that had a penalty added to the null space: bs="tp", "cs", or "ps" have this property.




## A brief foray into the land of Bayes
