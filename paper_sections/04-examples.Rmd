# IV: Examples

We now demonstrate two worked examples on one data set to highlight how to use HGAMs in practice, and to illustrate how to fit, test, and
visualize each model. We will demonstrate how to use these models to fit community
data, to show when using a global trend may or may not be justified, and to
illustrate how to use these models to fit seasonal time series.

For these examples, data are from a long-term study in seasonal dynamics of zooplankton, collected by the Richard Lathrop. The data were collected from a chain of lakes in Wisconsin (Mendota, Monona, Kegnonsa, and Waubesa) approximately bi-weekly from 1976 to 1994. They consist of samples of the zooplankton communities, taken from the deepest point of each lake via vertical tow. The data are provided by the Wisconsin Department of Natural Resources and their collection and processing are fully described in @lathrop_madison_2000.

Here inferential aims are *(i)* estimate variability in seasonality among species in the community in a single lake (Mendota), and *(ii)* estimate among-lake variability for the most abundant taxon in the sample (*Daphnia mendotae*) across the four lakes. As we are
focusing on seasonal cycles rather than average or maximum abundances. We have
log-transformed all densities, then centered and scaled them by the within year,
species and lake mean; all species in all lake-years will have a mean scaled density of zero and standard deviation of one. To enable evaluation of out-of-sample performance, we split the data into testing and training sets. As there are multiple years of data, so we use data from the even years to fit (train) models, and the odd years to test the fit.

```{r zoo_data, include = FALSE, message=FALSE,  cache=TRUE}
zooplankton <- read.csv("../data/zooplankton_example.csv") %>%
  mutate(year_f = factor(year))

#This is what the data looks like:
str(zooplankton)
levels(zooplankton$taxon)
levels(zooplankton$lake)

# We'll now break it into testing and training data. The training data will be
# used to fit the model, and the testing data will be used to evaluate model fit.
zoo_train <- subset(zooplankton, year%%2==0)
zoo_test <- subset(zooplankton, year%%2==1) 
```



Our step will be to demonstrate how to model community-level
variability in seasonality, by regressing scaled density on day of year, with
species-specific curves. As we are not interested here in average seasonal
dynamics, we will focus on models 4 and 5 (if we wanted to estimate the
seasonal dynamics for rarer species, adding a global smooth term might be
useful, so we could could borrow information from the more common species). As the data are seasonal,  we use cyclic smoothers as the basis for seasonal dynamics.  Therefore we need to specify start and end points for our cycles using the `knots` argument to `gam`, as well as specify that this is smoother type to the factor smooth using the `xt` argument:

### Model 4:

```{r zoo_comm_mod4, echo=TRUE, message=FALSE,  cache=TRUE, fig.width=8, fig.height=5}
zoo_comm_mod4 <- gam(density_adj ~ s(day, taxon,
                                     bs="fs",
                                     k=10,
                                     xt=list(bs="cc"))+
                                   s(taxon, bs="re") +
                                   s(taxon, year_f, bs="re"),
                     data=zoo_train,
                     knots = list(day =c(1, 365)),
                     family = Gamma(link ="log"), 
                     method = "ML",
                     drop.unused.levels = FALSE)
```


Note that we use maximum likelihood (`method = "ML"`) as our smoothing selection method. This is required as we want to compare models that differ in their fixed effects.

### Model 5:

```{r zoo_comm_mod5, echo=TRUE, message=FALSE,  cache=TRUE, fig.width=8, fig.height=5}
zoo_comm_mod5 <- gam(density_adj ~ s(day, by=taxon,
                                     k=10, bs="cc") + 
                                   s(taxon, bs="re") +
                                   s(taxon, year_f, bs="re"),
                     data=zoo_train,
                     knots = list(day =c(1, 365)),
                     family = Gamma(link ="log"), 
                     method = "ML",
                     drop.unused.levels = FALSE)
```

Both models have very similar fits, with a mean squared error of
`r round(var(residuals(zoo_comm_mod4)),2)`
for model 4 and
`r round(var(residuals(zoo_comm_mod5)),2)`
for model 5 (the mean squared error for the original data equals 1 because
of the scaling).  Model 5 has a somewhat lower AIC (`AIC(zoo_comm_mod4)` = `r as.integer(round(AIC(zoo_comm_mod4),0))`, `AIC(zoo_comm_mod5)` = `r as.integer(round(AIC(zoo_comm_mod5)))`), implying a better overall fit. However, the two models are almost indistinguishable when plotted on top of each other (Figure \ref{fig:zoo_comp}).

```{r zoo_comm_plot, echo=FALSE, message=FALSE, warning=TRUE, cache=TRUE,results="markup", fig.width=6, fig.height=6, fig.cap = "\\label{fig:zoo_comp}Species-specific seasonal dynamics for the eight zooplankon species tracked in Lake Mendota. Black points indicate individual plankton observations (after log-transformation and centering and scaling). Lines indicate predicted average values for model 4 (black) and model 5 (red). Ribbons indicate $\\pm$ 2 standard errors around the mean. "}
#Create synthetic data to use to compare predictions
zoo_plot_data = expand.grid(day = 1:365, taxon = factor(levels(zoo_train$taxon)), year_f =1980)

#extract predicted values and standard errors for both models
zoo_mod4_fit = predict(zoo_comm_mod4, zoo_plot_data, se.fit = T)
zoo_mod5_fit = predict(zoo_comm_mod5, zoo_plot_data, se.fit = T)

zoo_plot_data$mod4_fit = as.numeric(zoo_mod4_fit$fit)
zoo_plot_data$mod5_fit = as.numeric(zoo_mod5_fit$fit)

zoo_plot_data$mod4_se = as.numeric(zoo_mod4_fit$se.fit)
zoo_plot_data$mod5_se = as.numeric(zoo_mod5_fit$se.fit)

#Plot the model output, with means plus standard deviations for each model.
zoo_plot = ggplot(zoo_plot_data, aes(x=day))+
  facet_wrap(~taxon, nrow = 4,scales = "free_y")+
  geom_point(data= zoo_train, aes(y=density_adj),size=0.1)+
  geom_line(aes(y=exp(mod4_fit), color = "Model 4"))+
  geom_line(aes(y=exp(mod5_fit), color = "Model 5"))+
  geom_ribbon(aes(ymin = exp(mod4_fit - 2*mod4_se),
                  ymax = exp(mod4_fit + 2*mod4_se),
                  fill="Model 4"),
              alpha=0.25)+
  geom_ribbon(aes(ymin = exp(mod5_fit - 2*mod5_se),
                  ymax = exp(mod5_fit + 2*mod5_se),
                  fill="Model 5"),
              alpha=0.25)+
  scale_y_continuous("Population density\n(individuals/m^2)")+
  scale_x_continuous(expand = c(0,0))+
  scale_color_manual("", breaks = c("Model 4", "Model 5"), values = c("black","red"))+
  scale_fill_manual("", breaks = c("Model 4", "Model 5"), values = c("black","red"))+
  theme(legend.position = "bottom")

print(zoo_plot)
```

Model 5's higher AIC than model 4 seems to be driven by the low seasonality of *Keratella cochlearis* and *Leptodiaptomus siciloides* relative to the other species. Still, both
models show very similar fits to the training data. Model 5 is only slightly better at predicting out of sample fits for *K. cochlearis*, and not at all better for *L. siciloides*  (Table \ref{tab:zoo_comm_outofsample}).


```{r zoo_comm_outofsample, echo=FALSE, message=FALSE,  cache=TRUE}

#Getting the out of sample predictions for both models:

#This function calculates the sum of squared deviances for out-of-sample data
get_deviance = function(model,predicted, observed){
  res <- model$family$dev.resids(observed, predicted, wt=1)
  return(sum(res))
}



# we need to compare how well this model fits with a null model. here we'll use an
# intercept-only model
zoo_comm_mod0 <- gam(density_adj ~ s(taxon,bs="re") +
                                   s(taxon, year_f, bs="re"),
                     data=zoo_train,
                     knots = list(day =c(1, 365)),
                     family = Gamma(link ="log"), 
                     method = "ML",
                     drop.unused.levels = FALSE)

#Correlations between fitted and observed values for all species:
#\n is in variable titles to add a line break in the printed table.
zoo_test_summary = zoo_test %>%
  mutate(
    mod0 = predict(zoo_comm_mod0, ., type="response"),
    mod4 = predict(zoo_comm_mod4, ., type="response"),
    mod5 = predict(zoo_comm_mod5, ., type="response"))%>%
  group_by(taxon)%>%
  summarize(
    `Intercept only` = format(get_deviance(zoo_comm_mod0, mod0, density_adj), scientific = T, digits=2),
    `model 4` = format(get_deviance(zoo_comm_mod4, mod4, density_adj), scientific = T, digits=2),
    `model 5` = format(get_deviance(zoo_comm_mod5, mod5, density_adj), scientific = T, digits=2))

kable(zoo_test_summary, format = table_out_format, caption="Out-of-sample predictive ability for model 4 and 5 applied to the zooplankton community dataset. MSE values represent the average squared difference between model predictions and observations for test data.", booktabs = T)%>%
  kable_styling(full_width = F)
```

Now let's look at how to fit inter-lake variability in dynamics for just *Daphnia mendotae*.
Here, we will compare models 1, 2, and 3 to determine if a single global function
is appropriate for all four lakes, or if we can more effectively model variation between
lakes with a shared smooth and lake-specific smooths.



### Model 1:

```{r zoo_daph_mod1, echo=TRUE, message=FALSE,  cache=TRUE}
daphnia_train <- subset(zoo_train, taxon=="D. mendotae")
daphnia_test <- subset(zoo_test, taxon=="D. mendotae")

zoo_daph_mod1 <- gam(density_adj~s(day, bs="cc",k=10)+
                       s(lake, bs="re") + 
                       s(lake, year_f,bs="re"),
                     data=daphnia_train,
                     knots=list(day =c(1, 365)),
                     family=Gamma(link ="log"),
                     method="ML",
                     drop.unused.levels = FALSE)

printCoefmat(summary(zoo_daph_mod1)$s.table)
```

### Model 2:
```{r zoo_daph_mod2, echo=TRUE, message=FALSE,  cache=TRUE}
zoo_daph_mod2 <- gam(density_adj~s(day, bs="cc", k=10) +
                             s(day, lake, k=10, bs="fs",
                               xt=list(bs="cc"))+
                             s(lake, bs="re") + 
                             s(lake, year_f,bs="re"),
                     data=daphnia_train,
                     knots=list(day =c(1, 365)),
                     family=Gamma(link ="log"),
                     method="ML",
                     drop.unused.levels = FALSE)

printCoefmat(summary(zoo_daph_mod2)$s.table)
```

### Model 3:

```{r zoo_daph_mod3, echo=TRUE, message=FALSE,  cache=TRUE}
zoo_daph_mod3 <- gam(density_adj~s(day, bs="cc", k=10) +
                             s(day, by=lake, k=10, bs="cc")+
                             s(lake, bs="re") + 
                             s(lake, year_f,bs="re"),
                     data=daphnia_train,
                     knots=list(day =c(1, 365)),
                     family=Gamma(link ="log"),
                     method="ML",
                     drop.unused.levels = FALSE)

printCoefmat(summary(zoo_daph_mod3)$s.table)
```

The AIC values indicate that both model 2 (`r round(AIC(zoo_daph_mod2), 2)`) and 3
(`r round(AIC(zoo_daph_mod3), 2)`) are better fits than model 1 (`r round(AIC(zoo_daph_mod1), 2)`),
but models 2 and 3 have similar fits. There does not seem to be a
large amount of inter-lake variability (the effective degrees of freedom per
lake are low in models 2 & 3). Model 3 indicates that only Lake Waubesa
deviates substantially from the overall dynamics. Plots for all three models
(Figure \ref{fig:daph_smooth}) show that Mendota and Monona lakes are very close
to the average and to one another for both models (which is unsurprising, as they
are very closely connected by a short river), 
but both Kegonsa and Waubesa show
evidence of a more pronounced spring bloom and lower winter abundances.  While
this is stronger in Lake Waubesa, it is still detectable with simpler model 2 in Lake Kegonsa (Figure \ref{fig:daph_smooth}, black line).

```{r zoo_daph_plot, echo=FALSE, message=FALSE, warning=TRUE, cache=TRUE, fig.width=5, fig.height=4, fig.cap="\\label{fig:daph_smooth}Raw data (points) and fitted models (lines) for \textit{D. mendota} data. Dashed black line: model 1 (no inter-lake variation in dynamics); solid black line: model 2 (interlake variation with similar smoothness); red line: model 3 (varying smooths among lakes). Red and black ribbons indicate $\\pm$ 2 standard errors around each model."}
#Create synthetic data to use to compare predictions
daph_plot_data = expand.grid(day = 1:365, lake = factor(levels(zoo_train$lake)),year_f = 1980)


daph_mod1_fit = predict(zoo_daph_mod1, daph_plot_data, se.fit = T)
daph_mod2_fit = predict(zoo_daph_mod2, daph_plot_data, se.fit = T)
daph_mod3_fit = predict(zoo_daph_mod3, daph_plot_data, se.fit = T)


daph_plot_data$mod1_fit = as.numeric(daph_mod1_fit$fit)
daph_plot_data$mod2_fit = as.numeric(daph_mod2_fit$fit)
daph_plot_data$mod3_fit = as.numeric(daph_mod3_fit$fit)

daph_plot_data$mod1_se = as.numeric(daph_mod1_fit$se.fit)
daph_plot_data$mod2_se = as.numeric(daph_mod2_fit$se.fit)
daph_plot_data$mod3_se = as.numeric(daph_mod3_fit$se.fit)

daph_plot = ggplot(daph_plot_data, aes(x=day))+
  facet_wrap(~lake, nrow = 2)+
  geom_point(data= daphnia_train, aes(y=density_adj),size=0.1)+
  geom_line(aes(y=exp(mod1_fit), linetype = "Model 1", size = "Model 1"))+
  geom_line(aes(y=exp(mod2_fit),color = "Model 2"))+
  geom_line(aes(y=exp(mod3_fit),color = "Model 3"))+
  geom_ribbon(aes(ymin = exp(mod2_fit - 2*mod2_se),
                  ymax = exp(mod2_fit + 2*mod2_se),fill = "Model 2"),
              alpha=0.25)+
  geom_ribbon(aes(ymin = exp(mod3_fit - 2*mod3_se),
                  ymax = exp(mod3_fit + 2*mod3_se),fill = "Model 3"),
              alpha=0.25)+
  scale_y_continuous("Population density\n(individuals/m^2)")+
  scale_x_continuous(expand = c(0,0))+
  scale_color_manual("", breaks = c("Model 2", "Model 3"), values = c("black","red"))+
  scale_fill_manual("", breaks = c("Model 2", "Model 3"), values = c("black","red"))+
  scale_linetype_manual("", breaks = c("Model 1"), values = 2)+
  scale_size_manual("", breaks = c("Model 1"), values = 2)+
  theme(legend.position = "bottom")

print(daph_plot)
```


Model 2 is able to predict as well or better out of sample as
model 1 or 3 (Table \ref{tab:zoo_daph_outofsample}), indicating that jointly smoothing the lakes together improved model
prediction. None of the models did well in terms of predicting Lake
Kegonsa dynamics out of sample (with a MSE of between 0.95-0.99, compared to a MSE of the original data of 1),  indicating that this model may be be missing
substantial year-to-year variability in *D. mendotae* dynamics in this lake.

```{r zoo_daph_outofsample, echo=FALSE, message=FALSE,  cache=TRUE}
# we need to compare how well this model fits with a null model. here we'll use an
# intercept-only model
zoo_daph_mod0 <- gam(density_adj~s(lake, bs="re") + 
                                 s(lake, year_f,bs="re"),
                     data=daphnia_train,
                     knots=list(day =c(1, 365)),
                     family=Gamma(link ="log"),
                     method="ML",
                     drop.unused.levels = FALSE)



# We'll look at the correlation between fitted and observed values for all species:

daph_test_summary <- daphnia_test %>%
  mutate(#get out-of-sample predicted fits
    mod0 = as.numeric(predict(zoo_daph_mod0,.,type="response")),
    mod1 = as.numeric(predict(zoo_daph_mod1,.,type="response")),
    mod2 = as.numeric(predict(zoo_daph_mod2,.,type="response")),
    mod3 = as.numeric(predict(zoo_daph_mod3,.,type="response")))%>%
  group_by(lake)%>%
  summarise(`Raw` = format(get_deviance(zoo_daph_mod0, density_adj,mod0), scientific = T, digits=2),
            `model 1` = format(get_deviance(zoo_daph_mod1, density_adj,mod1), scientific = T, digits=2),
            `model 2` = format(get_deviance(zoo_daph_mod2, density_adj,mod2), scientific = T, digits=2),
            `model 3` = format(get_deviance(zoo_daph_mod3, density_adj,mod3), scientific = T, digits=2))

kable(daph_test_summary,format = table_out_format, caption="Out-of-sample predictive ability for model 1-3 applied to the \\textit{D. mendotae} dataset. MSE values represent the average squared difference between model predictions and observations for held-out data (zero predictive ability would correspond to a MSE of one).", booktabs = T)%>%
  kable_styling(full_width = F)
```
