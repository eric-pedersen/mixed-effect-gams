# IV: Examples

We now demonstrate two worked examples on one data set to highlight how to use HGAMs in practice, and to illustrate how to fit, test, and visualize each model.
We will demonstrate how to use these models to fit community data, to show when using a global trend may or may not be justified, and to
illustrate how to use these models to fit seasonal time series.

For these examples, data are from a long-term study in seasonal dynamics of zooplankton, collected by the Richard Lathrop. The data were collected from a chain of lakes in Wisconsin (Mendota, Monona, Kegnonsa, and Waubesa) approximately bi-weekly from 1976 to 1994. They consist of samples of the zooplankton communities, taken from the deepest point of each lake via vertical tow. The data are provided by the Wisconsin Department of Natural Resources and their collection and processing are fully described in @lathrop_madison_2000.

Here inferential aims are *(i)* estimate variability in seasonality among species in the community, and *(ii)* estimate between-lake variability for the most abundant taxon in the sample (*Daphnia mendotae*). As we are focusing on seasonal cycles rather than average or maximum abundances, we have
log-transformed all densities, then centered and scaled them by the within year,
species and lake means; all species in all lake-years will have a mean scaled density of zero and standard deviation of one. 

```{r view_zoo, include = FALSE, message=FALSE, cache=TRUE}
zooplankton <- read.csv("../data/zooplankton_example.csv")

#This is what the data looks like:
str(zooplankton)
levels(zooplankton$taxon)
levels(zooplankton$lake)
```

To enable evaluation of out-of-sample performance of the fitted HGAMs, we split the data into testing and training sets. As there are multiple years of data, we use data from the even years to fit (train) models, and the odd years to test the fit:

```{r zoo_train, echo=TRUE, message=FALSE,  cache=TRUE}
zoo_train <- subset(zooplankton, year%%2==0)
zoo_test <- subset(zooplankton, year%%2==1) 
```

First, we demonstrate how to model community-level variability in seasonality, by regressing scaled density on day of year, with species-specific curves. As we are not interested here in average seasonal dynamics, we will focus on models 4 and 5 (if we wanted to estimate the seasonal dynamics for rarer species, adding a global smooth term might be useful, so we could could borrow information from the more common species). As the data are seasonal,  we use cyclic smoothers as the basis for seasonal dynamics.  Therefore we need to specify start and end points for our cycles using the `knots` argument to `gam`, as well as specify that this is smoother type to the factor-smoother interaction term using the `xt` argument:

### Model 4:

```{r zoo_comm_mod4, echo=TRUE, message=FALSE,  cache=TRUE, fig.width=8, fig.height=5}
zoo_comm_mod4 <-
  gam(density_scaled ~ s(day, taxon, bs="fs", k=10, xt=list(bs="cc")),
      data=zoo_train, knots=list(day=c(0, 365)), method="ML")
```

Note that we use marginal likelihood (`method = "ML"`) as our smoothing selection method as we want to compare models that differ in their fixed effects.

### Model 5:

```{r zoo_comm_mod5, echo=TRUE, message=FALSE,  cache=TRUE, fig.width=8, fig.height=5}
zoo_comm_mod5 <-
  gam(density_scaled ~ taxon + s(day, by=taxon, k=10, bs="cc"),
      data=zoo_train, knots=list(day=c(0, 365)), method="ML")
```

Both models have very similar fits, with a mean squared error of `r round(var(residuals(zoo_comm_mod4)),2)` for model 4 and `r round(var(residuals(zoo_comm_mod5)),2)`
for model 5 (the mean squared error for the original data equals 1 because of the scaling).  Model 4 has a somewhat lower AIC (`AIC(zoo_comm_mod4)` = `r round(AIC(zoo_comm_mod4))`, `AIC(zoo_comm_mod5)` = `r round(AIC(zoo_comm_mod5))`), implying a better overall fit. However, the two models are almost indistinguishable when plotted on top of each other (Figure \ref{fig:zoo_comp}).

```{r zoo_comm_plot, echo=FALSE, message=FALSE, warning=TRUE, cache=TRUE, results="markup", fig.width=6, fig.height=4, fig.cap = "\\label{fig:zoo_comp}Species-specific seasonal dynamics for the eight zooplankon species tracked in Lake Mendota. Black points indicate individual plankton observations (after log-transformation and centering and scaling). Lines indicate predicted average values for model 4 (green) and model 5 (orange). Shaded bands are drawn at $\\pm$ 2 standard errors around the mean. "}
#Create synthetic data to use to compare predictions
zoo_plot_data <- expand.grid(day = 1:365, taxon = factor(levels(zoo_train$taxon)))

#extract predicted values and standard errors for both models
zoo_mod4_fit <- predict(zoo_comm_mod4, zoo_plot_data, se.fit = T)
zoo_mod5_fit <- predict(zoo_comm_mod5, zoo_plot_data, se.fit = T)

zoo_plot_data$mod4_fit <- as.numeric(zoo_mod4_fit$fit)
zoo_plot_data$mod5_fit <- as.numeric(zoo_mod5_fit$fit)

zoo_plot_data <- gather(zoo_plot_data, model, fit, mod4_fit, mod5_fit)

zoo_plot_data <- mutate(zoo_plot_data, se = c(as.numeric(zoo_mod4_fit$se.fit),
                                                as.numeric(zoo_mod5_fit$se.fit)),
                         upper = fit + (2 * se),
                         lower = fit - (2 * se))

zoo_plot <- ggplot(zoo_plot_data) +
    geom_point(aes(y=density_scaled, x = day), size=0.1, data = zoo_train) +
    geom_ribbon(aes(x = day, ymin = lower, ymax = upper, fill = model), 
                alpha = 0.2) +
    geom_path(aes(x = day, y = fit, colour = model)) +
    theme(legend.position = "top") +
    labs(y = "Scaled log-transformed density", x = "Day of Year") +
    facet_wrap(~ taxon, nrow = 2) +
    scale_fill_brewer(name = "", palette = "Dark2",
                      labels = paste("Model", 4:5)) +
    scale_colour_brewer(name = "",
                        palette = "Dark2", labels = paste("Model", 4:5))

zoo_plot
```

Differences between models seem to be driven by the low seasonality of *Keratella cochlearis* and *Leptodiaptomus siciloides* relative to the other species, and how this is captured by the more flexible model 5. Still, both models show very similar fits to the training data. Model 4 is slightly better at predicting out of sample fits for all taxa except Calanoid copepods (Table \ref{tab:zoo_comm_outofsample}).


```{r zoo_comm_outofsample, echo=FALSE, message=FALSE, cache=TRUE}
get_MSE = function(obs, pred) mean((obs-pred)^2)
#Getting the out of sample predictions for both models:
zoo_test$mod4 = as.numeric(predict(zoo_comm_mod4,zoo_test))
zoo_test$mod5 = as.numeric(predict(zoo_comm_mod5,zoo_test))

#Correlations between fitted and observed values for all species:
#\n is in variable titles to add a line break in the printed table.
zoo_test_summary = zoo_test %>%
  group_by(taxon)%>%
  summarise(`model 4 MSE` = round(get_MSE(density_scaled,mod4),2),
            `model 5 MSE` = round(get_MSE(density_scaled,mod5),2))

names(zoo_test_summary) <- c("Taxon", "Model 4 MSE", "Model 5 MSE")

kable(zoo_test_summary, format = table_out_format, caption="Out-of-sample predictive ability for model 4 and 5 applied to the zooplankton community dataset. MSE values represent the average squared difference between model predictions and observations for test data.", booktabs = TRUE)%>%
  kable_styling(full_width = FALSE)
```

Next, we look at how to fit inter-lake variability in dynamics for just *Daphnia mendotae*.
Here, we will compare models 1, 2, and 3 to determine if a single global function is appropriate for all four lakes, or if we can more effectively model variation between lakes with a shared smoother and lake-specific smoothers.

### Model 1:

```{r zoo_daph_mod1, echo=TRUE, message=FALSE, cache=TRUE}
daphnia_train <- subset(zoo_train, taxon=="D. mendotae")
daphnia_test <- subset(zoo_test, taxon=="D. mendotae")

zoo_daph_mod1 <-
  gam(density_scaled ~ s(day, bs="cc", k=10),
      data=daphnia_train, knots=list(day=c(0, 365)), method="ML")
printCoefmat(summary(zoo_daph_mod1)$s.table)
```

### Model 2:
```{r zoo_daph_mod2, echo=TRUE, message=FALSE,  cache=TRUE}
zoo_daph_mod2 <-
  gam(density_scaled ~ s(day, bs="cc", k=10) +
        s(day, lake, k=10, bs="fs", xt=list(bs="cc")),
      data=daphnia_train, knots=list(day=c(0, 365)), method="ML")
printCoefmat(summary(zoo_daph_mod2)$s.table)
```

### Model 3:

```{r zoo_daph_mod3, echo=TRUE, message=FALSE, cache=TRUE}
zoo_daph_mod3 <-
  gam(density_scaled ~ lake + s(day, bs="cc", k=10) + 
        s(day, by=lake, k=10, bs="cc", m=1),
      data=daphnia_train, knots=list(day=c(0, 365)), method="ML")
printCoefmat(summary(zoo_daph_mod3)$s.table)
```

The AIC values indicate that both model 2 (`r round(AIC(zoo_daph_mod2), 2)`) and 3
(`r round(AIC(zoo_daph_mod3), 2)`) are better fits than model 1 (`r round(AIC(zoo_daph_mod1), 2)`),
but models 2 and 3 have similar fits. There does not seem to be a large amount of inter-lake variability (the effective degrees of freedom per lake are low in models 2 & 3). Model 3 indicates that only Lake Waubesa deviates substantially from the overall dynamics. Plots for all three models
(Figure \ref{fig:daph_smooth}) show that Mendota and Monona lakes are very close to the average and to one another for both models (which is unsurprising, as they are very closely connected by a short river), but both Kegonsa and Waubesa show evidence of a more pronounced spring bloom and lower winter abundances.  While this is stronger in Lake Waubesa, it is still detectable with the simpler model 2 in Lake Kegonsa (Figure \ref{fig:daph_smooth}, orange line).

```{r zoo_daph_plot, echo=FALSE, message=FALSE, warning=TRUE, cache=TRUE, fig.width=6, fig.height=4, fig.cap="\\label{fig:daph_smooth}Raw data (points) and fitted models (lines) for \\textit{D. mendota} data. Green: model 1 (no inter-lake variation in dynamics); orange: model 2 (interlake variation with similar smoothness); purple: model 3 (varying smoothness among lakes). Shaded bands are drawn at $\\pm$ 2 standard errors around each model."}
#Create synthetic data to use to compare predictions
daph_plot_data <- expand.grid(day = 1:365, lake = factor(levels(zoo_train$lake)))

daph_mod1_fit <- predict(zoo_daph_mod1, daph_plot_data, se.fit = TRUE)
daph_mod2_fit <- predict(zoo_daph_mod2, daph_plot_data, se.fit = TRUE)
daph_mod3_fit <- predict(zoo_daph_mod3, daph_plot_data, se.fit = TRUE)

daph_plot_data$mod1_fit <- as.numeric(daph_mod1_fit$fit)
daph_plot_data$mod2_fit <- as.numeric(daph_mod2_fit$fit)
daph_plot_data$mod3_fit <- as.numeric(daph_mod3_fit$fit)

daph_plot_data <- gather(daph_plot_data, model, fit, mod1_fit, mod2_fit, mod3_fit)

daph_plot_data <- mutate(daph_plot_data, se = c(as.numeric(daph_mod1_fit$se.fit),
                                                as.numeric(daph_mod2_fit$se.fit),
                                                as.numeric(daph_mod3_fit$se.fit)),
                         upper = fit + (2 * se),
                         lower = fit - (2 * se))

daph_plot <- ggplot(daph_plot_data) +
    geom_point(aes(y=density_scaled, x = day), size=0.1, data = daphnia_train) +
    geom_ribbon(aes(x = day, ymin = lower, ymax = upper, fill = model), 
                alpha = 0.2) +
    geom_path(aes(x = day, y = fit, colour = model)) +
    theme(legend.position = "top") +
    labs(y = "Scaled log-transformed density", x = "Day of Year") +
    facet_wrap(~ lake, nrow = 2) +
    scale_fill_brewer(name = "", palette = "Dark2",
                      labels = paste("Model", 1:3)) +
    scale_colour_brewer(name = "",
                        palette = "Dark2", labels = paste("Model", 1:3))

daph_plot
```

Model 2 is able to predict as well or better out of sample as model 1 or 3 (Table \ref{tab:zoo_daph_outofsample}), indicating that jointly smoothing the lakes together improved model prediction. None of the models did well in terms of predicting Lake Kegonsa dynamics out of sample (with a MSE of between 0.95--0.99, compared to a MSE of the original data of 1), indicating that this model may be be missing substantial year-to-year variability in *D. mendotae* dynamics in this lake.

```{r zoo_daph_outofsample, echo=FALSE, message=FALSE,  cache=TRUE}
#Getting the out of sample predictions for both models:
daphnia_test$mod1 = as.numeric(predict(zoo_daph_mod1,daphnia_test))
daphnia_test$mod2 = as.numeric(predict(zoo_daph_mod2,daphnia_test))
daphnia_test$mod3 = as.numeric(predict(zoo_daph_mod3,daphnia_test))

# We'll look at the correlation between fitted and observed values for all species:
daph_test_summary = daphnia_test %>%
  group_by(lake)%>%
  summarise(`model 1 MSE` = round(get_MSE(density_scaled,mod1),2),
            `model 2 MSE` = round(get_MSE(density_scaled,mod2),2),
            `model 3 MSE` = round(get_MSE(density_scaled,mod3),2))

kable(daph_test_summary,format = table_out_format, caption="Out-of-sample predictive ability for model 1-3 applied to the \\textit{D. mendotae} dataset. MSE values represent the average squared difference between model predictions and observations for held-out data (zero predictive ability would correspond to a MSE of one).", booktabs = TRUE)%>%
  kable_styling(full_width = FALSE)
```
